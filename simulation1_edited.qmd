---
title: "Simulation with the Smallest Lambda for IpaB IgG"
format: 
  pdf:
    number-sections: true
    number-depth: 2
    number-offset: [0, 0]
editor: visual
output:
  pdf_document:
    orientation: landscape
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE,echo=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message=FALSE}
library(future.apply)
library(future)
library(gridExtra)
library(mgcv)  # For advanced GAM smoothing
library(haven)
library(knitr)
library(plotly)
library(kableExtra)
library(tidyr)
library(arsenal)
library(dplyr)
library(forcats)
library(huxtable)
library(magrittr)
library(parameters)
library(kableExtra)
library(ggplot2)
library(ggeasy)
library(scales)
library(plotly)
library(patchwork)
library(tidyverse)
library(gtsummary)
library(readxl)
library(purrr)
library(serocalculator)
library(runjags)
library(coda)
library(ggmcmc)
library(here)
library(bayesplot)
library(table1)
library(tibble)
library(furrr)
library(dplyr)
```


# Vary simulation lambdas across the range in the real cross-sectional data

## 1. Estimate the shigella incidence rate using the real cross-sectional Shigella data, 
```{r,echo=FALSE, message=FALSE, warning=FALSE,results='hide'}
##    separately for each geographic region in the data. 

# load shigella data
df <- read_excel("3.8.2024 Compiled Shigella datav2.xlsx", 
                 sheet = "Compiled")


# create function for generating specific region data
create_xs_data <- function(df, filter_countries, filter_antigen_iso, value_col) {
  df %>%
    # First, create/rename columns
    mutate(
      id = sid,
      Country = site_name,
      study   = study_name,
      age     = age,
      antigen_iso = factor(isotype_name),
      value   = {{ value_col }}  # value_col is specified by the user, e.g. n_ipab_MFI
    ) %>%
    # Then filter by the desired catchment(s) and antigen iso(s)
    filter(
      Country %in% filter_countries,
      antigen_iso %in% filter_antigen_iso
    ) %>%
    # Create age categories
    mutate(
      ageCat = factor(case_when(
        age < 5             ~ "<5",
        age >= 5 & age <=15  ~ "5-15",
        age > 15            ~ "16+"
      ))
    ) %>%
    # Optionally select only the needed columns
    select(id, Country, study, age, antigen_iso, value, ageCat)
}

# Cross-sectional data: MA USA, ipab_IgG
df_xs_USA_ipab_IgG <- create_xs_data(
  df,
  filter_countries = c("MA USA"),
  filter_antigen_iso = c("IgG"),
  value_col = n_ipab_MFI
)

# Cross-sectional data: MA USA, ipab_IgA

# Cross-sectional data: Ghana, ipab_IgG
df_xs_Ghana_ipab_IgG <- create_xs_data(
  df,
  filter_countries = c("Ghana"),
  filter_antigen_iso = c("IgG"),
  value_col = n_ipab_MFI
)

# Cross-sectional data: Ghana, ipab_IgA

# Cross-sectional data: Niger, ipab_IgG
df_xs_Niger_ipab_IgG <- create_xs_data(
  df,
  filter_countries = c("Niger"),
  filter_antigen_iso = c("IgG"),
  value_col = n_ipab_MFI
)

# Cross-sectional data: Niger, ipab_IgA

# Cross-sectional data: Sierra Leone, ipab_IgG
df_xs_Sierra_ipab_IgG <- create_xs_data(
  df,
  filter_countries = c("Sierra Leone"),
  filter_antigen_iso = c("IgG"),
  value_col = n_ipab_MFI
)

# Cross-sectional data: Sierra Leone, ipab_IgA

# Create function to clearly define cross-sectional data
prepare_df_for_serocalculator <- function(df, age_col = "age", value_col = "value") {
  # Ensure correct column names
  df <- df %>%
    rename(age = all_of(age_col))
  
  # Assign attributes for serocalculator
  attr(df, "age_var") <- "age"
  attr(df, "value_var") <- value_col
  
  # Check if serocalculator recognizes attributes
  get_value_var <- serocalculator:::get_value_var
  detected_value_var <- get_value_var(df)
  
  if (is.null(detected_value_var)) {
    warning("serocalculator did not detect the 'value' column. Check column naming.")
  } else {
    message("serocalculator recognized 'value' column: ", detected_value_var)
  }
  
  return(df)
}

# Application
df_xs_USA_ipab_IgG <- prepare_df_for_serocalculator(df_xs_USA_ipab_IgG)
df_xs_Ghana_ipab_IgG<- prepare_df_for_serocalculator(df_xs_Ghana_ipab_IgG)
df_xs_Niger_ipab_IgG<- prepare_df_for_serocalculator(df_xs_Niger_ipab_IgG)
df_xs_Sierra_ipab_IgG<- prepare_df_for_serocalculator(df_xs_Sierra_ipab_IgG)
```



## Get parameters from longitudinal data
```{r,echo=FALSE, message=FALSE, warning=FALSE,results='hide'}
# Define a function to filter and manipulate Shigella data
process_shigella_data <- function(data, study_filter, antigen) {
  # Filter the data for the specific study
  filtered_data <- data %>% 
    filter(study_name == study_filter)
  
  # Capture the column name of the antigen
  antigen_col <- ensym(antigen)
  
  # Manipulate and restructure the data
  processed_data <- filtered_data %>%
    select(isotype_name, sid, timepoint, `Actual day`, !!antigen_col) %>%
    mutate(
      index_id = sid,
      antigen_iso = isotype_name,
      visit = timepoint,
      timeindays = `Actual day`,
      result = !!antigen_col
    ) %>%
    group_by(index_id, antigen_iso) %>%
    arrange(visit) %>%
    mutate(visit_num = rank(visit, ties.method = "first")) %>%
    ungroup() %>%
    # Remove rows with NA in timeindays
    filter(!is.na(timeindays))
  
  return(processed_data)
}


dL_clean <- process_shigella_data(data = df, study_filter = "SOSAR", antigen = n_ipab_MFI)


# Construct the path to "prep_data.r" using here
prep_data_path <- here::here("R", "prep_data.r")
prep_priors_path <- here::here("R", "prep_priors.R")

# Source the file to load the prep_data function
source(prep_data_path)
source(prep_priors_path)

#prepare data for modeline
# Create 5 different longdata
longdata <- prep_data(dL_clean)
priors <- prep_priors(max_antigens = longdata$n_antigen_isos)


nchains <- 4;                # nr of MC chains to run simultaneously
nadapt  <- 1000;             # nr of iterations for adaptation
nburnin <- 100;            # nr of iterations to use for burn-in
nmc     <- 100;             # nr of samples in posterior chains
niter   <- 200;            # nr of iterations for posterior sample
nthin   <- round(niter/nmc); # thinning needed to produce nmc from niter

tomonitor <- c("y0", "y1", "t1", "alpha", "shape");

#This handles the seed to reproduce the results 
initsfunction <- function(chain){
  stopifnot(chain %in% (1:4)); # max 4 chains allowed...
  .RNG.seed <- (1:4)[chain];
  .RNG.name <- c("base::Wichmann-Hill","base::Marsaglia-Multicarry",
                 "base::Super-Duper","base::Mersenne-Twister")[chain];
  return(list(".RNG.seed"=.RNG.seed,".RNG.name"=.RNG.name));
}

file.mod <- here::here("inst", "extdata", "model.jags.r")

set.seed(11325)
jags.post <- run.jags(model = file.mod, 
                      data = c(longdata, priors),
                      inits = initsfunction,
                      method = "parallel",
                      adapt = nadapt,
                      burnin = nburnin,
                      thin = nthin,
                      sample = nmc,
                      n.chains = nchains,
                      monitor = tomonitor,
                      summarise = FALSE)

mcmc_list <- as.mcmc.list(jags.post)

mcmc_df <- ggs(mcmc_list)

wide_predpar_df <- mcmc_df %>%
  mutate(
    parameter = sub("^(\\w+)\\[.*", "\\1", Parameter),
    index_id = as.numeric(sub("^\\w+\\[(\\d+),.*", "\\1", Parameter)),
    antigen_iso = as.numeric(sub("^\\w+\\[\\d+,(\\d+).*", "\\1", Parameter))
  ) %>%
  mutate(
    index_id = factor(index_id, labels = c(unique(dL_clean$index_id), "newperson")),
    antigen_iso = factor(antigen_iso, labels = unique(dL_clean$antigen_iso))) %>%
  filter(index_id == "newperson") %>%
  select(-Parameter) %>%
  pivot_wider(names_from = "parameter", values_from="value") %>%
  rowwise() %>%
  droplevels() %>%
  ungroup() %>%
  rename(r = shape)

# Assuming wide_predpar_df is your data frame
curve_params <- wide_predpar_df

# Set class and attributes for serocalculator
class(curve_params) <- c("curve_params", class(curve_params))
antigen_isos <- unique(curve_params$antigen_iso)
attr(curve_params, "antigen_isos") <- antigen_isos

curve_params<-curve_params%>%
  mutate(
    iter=Iteration)%>%
  select(antigen_iso,iter,y0,y1,t1,alpha,r)

curve_params_shigella<-curve_params
```

```{r,echo=FALSE, message=FALSE, warning=FALSE,results='hide'}
## Set noise 
create_noise_df <- function(country) {
  noise_df <- tibble(
    antigen_iso = c("IgG"),
    Country     = factor(c(country)),  # Use input argument for Country
    y.low       = c(25),
    eps         = c(0.25),
    nu          = c(0.5),
    y.high      = c(200000)
  )
  
  return(noise_df)
}

noise_df_USA <- create_noise_df("MA USA")
noise_df_Niger <- create_noise_df("Niger")
noise_df_Sierra <- create_noise_df("Sierra Leone")
noise_df_Ghana <- create_noise_df("Ghana")
```

## 2. Run simulations using: 
```{r,echo=FALSE, message=FALSE, warning=FALSE}
# MA USA
est_USA <- est.incidence(
  pop_data = df_xs_USA_ipab_IgG,
  curve_params = curve_params_shigella,
  noise_params = noise_df_USA,
  antigen_isos = c("IgG"),
)

# Ghana
est_Ghana <- est.incidence(
  pop_data = df_xs_Ghana_ipab_IgG,
  curve_params = curve_params_shigella,
  noise_params = noise_df_Ghana,
  antigen_isos = c("IgG"),
)

# Niger
est_Niger <- est.incidence(
  pop_data = df_xs_Niger_ipab_IgG,
  curve_params = curve_params_shigella,
  noise_params = noise_df_Niger,
  antigen_isos = c("IgG"),
)

# Sierra Leone
est_Sierra <- est.incidence(
  pop_data = df_xs_Sierra_ipab_IgG,
  curve_params = curve_params_shigella,
  noise_params = noise_df_Sierra,
  antigen_isos = c("IgG"),
)

# create table of incidence.rate of each region

create_incidence_table <- function(...) {
  # Capture input objects and their names
  est_list <- list(...)
  country_names <- names(est_list)
  
  # Extract incidence.rate from the summary() of each estimate object
  incidence_rates <- sapply(est_list, function(x) summary(x)$incidence.rate)
  
  # Create a tidy tibble
  incidence_table <- tibble(
    Country = country_names,
    Incidence_Rate = incidence_rates
  )
  
  return(incidence_table)
}
# Example usage with four different country estimates:
incidence_summary <- create_incidence_table(
  USA = est_USA,
  Ghana = est_Ghana,
  Niger = est_Niger,
  Sierra_Leone = est_Sierra
)

# Display the summary table
print(incidence_summary)

# 1) The median of the incidence rate estimates from step 1.
# Get incidence rate estimates from each region (4 regions) and do median
med_ipab_IgG<-median(incidence_summary$Incidence_Rate)
med_ipab_IgG
#1.188

# 2) 2x the maximum incidence rate estimate from step 1
# Get incidence rate estimates from each region (4 regions) and get the maximum one and 2x
max2_ipab_IgG<-2*max(incidence_summary$Incidence_Rate)
max2_ipab_IgG
# 2.788

# 3) 1/2 the minimum incidence rate from step 1
# Get incidence rate estimates from each region (4 regions) and get the minimum one and 1/2
min_half_ipab_IgG<-0.5*min(incidence_summary$Incidence_Rate)
min_half_ipab_IgG
#0.185

```
These three values are preliminary observations of lambda from ipab_IgG.

We choose a lambda that is half of the minimum lambda from the four regions.
 

# Simulation (200times) with the smallest lambda
```{r,echo=FALSE, message=FALSE, warning=FALSE,results='hide'}

# Define the simulation function
simulate_seroincidence <- function(nrep, n_sim, observed, range = NULL, batch_size = 40, parallel = TRUE) {
  # Parameters
  dmcmc <- curve_params_shigella  # Curve parameters
  antibodies <- c("IgG")  # Antigen-isotypes
  lambda <- observed  # Simulated incidence rate per person-year
  
  # Biologic noise distribution
  dlims <- rbind(
    "IgG" = c(min = 0, max = 0.5)
  )
  
  # Noise parameters
  cond <- tibble(
    antigen_iso = c("IgG"),
    nu = c(0.5),  
    eps = c(0.25),     
    y.low = c(25),   
    y.high = c(200000)  
  )

  # Calculate number of batches
  n_batches <- ceiling(n_sim / batch_size)
  
  # Parallel processing: Use future_map for efficiency
  if (parallel) {
    plan(multisession, workers = max(1, future::availableCores() - 1))
    
    results <- future_map(1:n_batches, function(batch) {
      # Run simulations within each batch
      replicate(batch_size, expr = {
        csdata <- sim.cs(
          curve_params = dmcmc,
          lambda = lambda,
          n.smpl = nrep,
          age_range = range,
          antigen_isos = antibodies,
          n.mc = 0,
          renew_params = FALSE,  # Keep the same params for speed
          add.noise = TRUE,
          noise_limits = dlims,
          format = "long"
        )
        
        # Estimate seroincidence
        est <- est.incidence(
          pop_data = csdata,
          curve_params = dmcmc,
          noise_params = cond,
          lambda_start = 0.1,
          build_graph = FALSE,  # Disable visualization for speed
          verbose = FALSE,
          print_graph = FALSE,
          antigen_isos = antibodies
        )
        
        list(csdata = csdata, est1 = est)
      }, simplify = FALSE)  # Keep list structure
    }, .options = furrr_options(seed = TRUE))  # Set seed for reproducibility
    
    # Flatten nested list
    results <- unlist(results, recursive = FALSE)
    
  } else {
    # Sequential execution (for debugging or single-core use)
    results <- lapply(1:n_sim, function(i) {
      csdata <- sim.cs(
        curve_params = dmcmc,
        lambda = lambda,
        n.smpl = nrep,
        age_range = range,
        antigen_isos = antibodies,
        n.mc = 0,
        renew_params = FALSE,  
        add.noise = TRUE,
        noise_limits = dlims,
        format = "long"
      )
      
      est <- est.incidence(
        pop_data = csdata,
        curve_params = dmcmc,
        noise_params = cond,
        lambda_start = 0.1,
        build_graph = FALSE,  
        verbose = FALSE,
        print_graph = FALSE,
        antigen_isos = antibodies
      )
      
      list(csdata = csdata, est1 = est)
    })
  }
  
  return(results)
}

```

```{r,echo=FALSE, message=FALSE, warning=FALSE,results='hide'}
# Run the optimized simulations with n_sim = 200
set.seed(206251)

results_100_1 <- simulate_seroincidence(nrep = 100, n_sim = 200,  
                                        observed = min_half_ipab_IgG, range = c(0,2),
                                        batch_size = 40)

results_100_2 <- simulate_seroincidence(nrep = 100, n_sim = 200,  
                                        observed = min_half_ipab_IgG, range = c(2,5),
                                        batch_size = 40)

results_200_1 <- simulate_seroincidence(nrep = 200, n_sim = 200,  
                                        observed = min_half_ipab_IgG, range = c(0,2),
                                        batch_size = 40)

results_200_2 <- simulate_seroincidence(nrep = 200, n_sim = 200,  
                                        observed = min_half_ipab_IgG, range = c(2,5),
                                        batch_size = 40)

results_300_1 <- simulate_seroincidence(nrep = 300, n_sim = 200,  
                                        observed = min_half_ipab_IgG, range = c(0,2),
                                        batch_size = 40)

results_300_2 <- simulate_seroincidence(nrep = 300, n_sim = 200,  
                                        observed = min_half_ipab_IgG, range = c(2,5),
                                        batch_size = 40)

results_400_1 <- simulate_seroincidence(nrep = 400, n_sim = 200,  
                                        observed = min_half_ipab_IgG, range = c(0,2),
                                        batch_size = 40)

results_400_2 <- simulate_seroincidence(nrep = 400, n_sim = 200,  
                                        observed = min_half_ipab_IgG, range = c(2,5),
                                        batch_size = 40)

# Stop parallel processing to free memory
plan(sequential)
```


## Store each sample size in table
```{r,echo=FALSE, message=FALSE, warning=FALSE,results='hide'}
# Define a function to generate final tables
generate_final_table <- function(results_list, sample_size) {
  # Initialize an empty list to store the results
  summary_results <- list()
  
  # Loop through each of the 100 results and extract the required columns
  for (i in 1:200) {
    # Extract the summary for each result
    result_summary <- summary(results_list[[i]]$est1)
    
    # Select the required columns
    extracted_columns <- result_summary %>%
      select(incidence.rate, SE, CI.lwr, CI.upr)
    
    # Add a column for the index (optional, for tracking)
    extracted_columns <- extracted_columns %>%
      mutate(index = i)
    
    # Append to the list
    summary_results[[i]] <- extracted_columns
  }
  
  # Combine all results into a single data frame
  final_table <- bind_rows(summary_results) %>%
    mutate(sample_size = sample_size) # Add sample size column for clarity
  
  return(final_table)
}

# Example usage for different sample sizes
final_table_100_1 <- generate_final_table(results_100_1, 100)
final_table_100_2 <- generate_final_table(results_100_2, 100)

final_table_200_1 <- generate_final_table(results_200_1, 200)
final_table_200_2 <- generate_final_table(results_200_2, 200)

final_table_300_1 <- generate_final_table(results_300_1, 300)
final_table_300_2 <- generate_final_table(results_300_2, 300)

final_table_400_1 <- generate_final_table(results_400_1, 400)
final_table_400_2 <- generate_final_table(results_400_2, 400)
```



## Graphs of where the x axis is the sample size and the y axis is the empirical standard error

Set the preliminary observed lambda as half of the minimum incidence rate from the four regions.

```{r,echo=FALSE, message=FALSE, warning=FALSE}
# Function to calculate metrics for each table
calculate_metrics <- function(data, sample_size) {
  empirical_se <- sd(data$incidence.rate)
  
  
  # Return a data frame with results
  data.frame(
    sample_size = sample_size,
    empirical_se = empirical_se
    
  )
}

# Apply the function to each table
metrics_100_1 <- calculate_metrics(final_table_100_1, 100)
metrics_100_2 <- calculate_metrics(final_table_100_2, 100)

metrics_200_1 <- calculate_metrics(final_table_200_1, 200)
metrics_200_2 <- calculate_metrics(final_table_200_2, 200)

metrics_300_1 <- calculate_metrics(final_table_300_1, 300)
metrics_300_2 <- calculate_metrics(final_table_300_2, 300)

metrics_400_1 <- calculate_metrics(final_table_400_1, 400)
metrics_400_2 <- calculate_metrics(final_table_400_2, 400)


# Combine the results into a single summary table
summary_metrics_1 <- bind_rows(metrics_100_1, metrics_200_1, metrics_300_1,
                               metrics_400_1)


summary_metrics_2 <- bind_rows(metrics_100_2, metrics_200_2, metrics_300_2,
                               metrics_400_2)

# Add a column to distinguish the datasets
summary_metrics_1 <- summary_metrics_1 %>%
  mutate(Age_Group = "Age 0-2")

summary_metrics_2 <- summary_metrics_2 %>%
  mutate(Age_Group = "Age 2-5")

# Combine both datasets into one
summary_metrics_combined <- bind_rows(summary_metrics_1, summary_metrics_2)

# Plot with color to differentiate age groups
ggplot(summary_metrics_combined, aes(x = sample_size, y = empirical_se, color = Age_Group)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Empirical Standard Error vs. Sample Size",
    x = "Sample Size",
    y = "Empirical Standard Error",
    color = "Age Group"
  ) +
  theme_minimal()
```


## Table

```{r,echo=FALSE, message=FALSE, warning=FALSE}
summary_metrics_combined %>%
  kable()
```
